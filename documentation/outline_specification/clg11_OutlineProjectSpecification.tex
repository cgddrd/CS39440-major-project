\documentclass[10pt,fleqn,twoside]{article}
\usepackage{makeidx}
\makeindex
\usepackage{palatino} %or {times} etc
\usepackage{plain} %bibliography style 
\usepackage{amsmath} %math fonts - just in case
\usepackage{amsfonts} %math fonts
\usepackage{amssymb} %math fonts
\usepackage{lastpage} %for footer page numbers
\usepackage{fancyhdr} %header and footer package
\usepackage{mmp_cg} 
\usepackage{url}

% the following packages are used for citations - You only need to include one. 
%
% Use the cite package if you are using the numeric style (e.g. IEEEannot). 
% Use the natbib package if you are using the author-date style (e.g. authordate2annot). 
% Only use one of these and comment out the other one. 
\usepackage{cite}
%\usepackage{natbib}

\begin{document}

\name{Connor Goddard}
\userid{clg11}
\projecttitle{Estimation of Terrain Shape Using a Monocular Vision-based System}
\projecttitlememoir{Estimation of Terrain Shape Using a Monocular Vision-based System} %same as the project title or abridged version for page header
\reporttitle{Outline Project Specification}
\version{0.3}
\docstatus{Draft}
\modulecode{CS39440}
\degreeschemecode{G601}
\degreeschemename{MEng Software Engineering}
\supervisor{Dr. Fr\'ed\'eric Labrosse} % e.g. Neil Taylor
\supervisorid{ffl}
\wordcount{1505}

%optional - comment out next line to use current date for the document
%\documentdate{10th February 2014} 
\mmp

\setcounter{tocdepth}{3} %set required number of level in table of contents


%==============================================================================
\section{Project description}
%==============================================================================

\subsection{Background}

For a robot requiring autonomous motion or travelling capabilities, the task of navigating through a (typically) unknown environment is one that plays a fundamental role in ensuring such a device can successfully make safe, yet objective decisions on how best to traverse from a starting location to a target location, over typically uneven and/or poorly modelled terrain. \\

%As a problem-space, autonomous navigation can be de-composed into two key areas of focus; one of \textit{reactive} navigation, and the other of \textit{deliberative} navigation. Reactive, or local navigation is concerned with controlling the path of the robot through the immediate surrounding area, in particular focussing on the safe traversal around dangerous terrain hazards including obstacles and precipices. In contrast, deliberative or global navigation is tasked with planning the ``higher-level" path that a robot will follow top reach its destination, and as such, tends to adopt a greater level of focus on calculating the most \textit{optimal} path through the environment over necessarily the one that is ``safest" for the robot. Traditionally within autonomous navigation systems, feedback from both the reactive and deliberative components are combined in order to arrive at final path that balances both safety and objectivity. \\

The identification and subsequent avoidance of obstacles is naturally a crucial ability for an autonomous mobile robot to possess in order to help to maximise its own chances of survival. As a result, it is a keen and well-explored area of robotics research, with a variety of approaches now available adopting many types of sensor including sonar and laser scanning. An alternative approach that has enjoyed increasingly greater research focus over the past decade is that of vision-based obstacle avoidance, involving the analysis of images captured from one or more digital cameras in order to identify possible dangers currently situated within the robot's field of view. \\

Cameras are becoming an increasingly favourable sensor for use on robotic systems, due primarily to the impressive variety and quantity of potential data that can be captured \textit{simultaneously} from a single device. They are also one of few sensors that have experienced a consistent reduction in price over the past decade, making them viable for many types of project application and budget. \\

Many solutions to vision-based obstacle avoidance have been suggested and published, with the majority proposing novel approaches of amalgamating ``standard" computer-vision algorithms (e.g. optical flow, feature tracking or patch tracking) in order to improve on previously published detection or performance results, or to focus on specific types of obstacle avoidance (e.g. precipice or animal detection).

\subsection{Project Overview}

Combining recent advances in camera technology with appropriate computer vision algorithms and technique, the proposed project aims to design and implement a vision-based software application capable of estimating the general ``shape" of the terrain currently in front of a moving robot as it follows a route through its environment. Through this system it should be possible to identify the presence of both positive, and negative obstacles (e.g. rocks and pits respectively), providing a reasonable indication of their general size and location. \\

In addition, it is predicted that such a system will also be able to provide an estimation of the speed and change in rotation/orientation of the robot as it traverses along a path. These will be calculated as by-products of the terrain inference mechanism, and could form part of a larger visual odometry system. \\

While the primary aims of the proposed project are certainly research-focussed, the ultimate goal of the project would be to implement the system onto a working mobile robot, such as the `IDRIS' four wheeled all-terrain robot currently in operation at the Aberystwyth University Computer Science department. \\

Although at the time of writing there is still much discussion to be had as to the exact implementation details, it is generally expected that the system will adopt image patch-based tracking and correspondence to allow for the establishment of the general motion trend (i.e. optical flow) of the ground (or the egomotion of the robot).

%While there is no doubt that many similar vision-based systems have been produced previously, it does not appear that any of these systems have adopted appearance-based patch tracking in such a way as to prevent the need to provide a ``rigid" calibration model in exchange for an incremental, more flexible calibration procedure. 


%==============================================================================
\section{Proposed Tasks}
%==============================================================================

%Forming part of the project scope analysis, this section details a list of key tasks identified as necessary in order to achieve the aims of the proposed project. To provide as realistic a prediction as possible, any  potential approaches (and associated issues) identified, along with a prediction of current developer knowledge have been taken into account.

\begin{enumerate}
	\item \textbf{Research \& Analysis of Existing Computer Vision Approaches} -  A thorough analysis of previously published work with similar aims to the proposed project will be conducted to identify the key strengths and weaknesses of these various approaches, so that an informed decision can be made as to the most appropriate computer-vision methods for the purposes of the project. Particular attention will be focussed on the comparison between appearance-based, and feature-based tracking as a mechanism for determining the distance travelled between subsequent images. 
	
	\item \textbf{Project \& System Planning} - Following the completion of an appropriate analysis of existing techniques, algorithms and hardware/software technologies, this information will be feed into discussions with the project supervisor to plan and confirm the exact details of what the proposed system will do, and the approach to be taken in its implementation.

	\item \textbf{Investigation of Software Technologies} - An investigation into suitable programming languages and (if appropriate) third-party libraries will be conducted prior to beginning design work. Factors including recommendations from published work and robot hardware requirements will need to be taken into consideration.
	
	\item \textbf{Investigation of Hardware Technologies} - Decisions around the selection of hardware will need to be made, focussing mainly on the type and number of cameras. These will be influenced primarily by the choice of computer-vision methods and the existing hardware available.

	\item \textbf{System Design} - Architectural and component-level designs will be produced, detailing the structure of the software and hardware aspects individually, along with the interactions between the two.
	
	\item \textbf{Testing Design} - Given the research-based nature of the project, appropriate testing strategies will require careful planning and design. This is to ensure robust evaluation of the ``successes" of the system processes and methods in addressing the project aims (e.g qualitative vs quantitative evaluation).
	
	\item \textbf{System Implementation} - All code will be versioned and checked-in against work items. The project is expected to follow the SCRUM agile-methodology approach to development, with work broken-down into time-boxed releases and subsequent sprints. 
	
	\item \textbf{System Testing \& Evaluation} - A significant level of attention is expected to focus on testing of the computer-vision approach/algorithms using ``ground truth" testing data as a primary measure. However, extensive software testing will also be conducted incorporating unit testing, testing tables, and possibly continuous integration testing (if appropriate).
	
	\item \textbf{Production of Final Report} - A 20,000-word report will be written describing and justifying all aspects of the major project including the planning, design, implementation, testing and evaluation.
	
	\item \textbf{Logging of Work} - Throughout the entirety of the project, any key thoughts or notes will be published to a live web-blog available at: \url{http://mmpblog.connorlukegoddard.com}. This blog will act as a memory aid when writing the final report.

\end{enumerate}


%==============================================================================
\section{Project Deliverables}
%==============================================================================

\begin{enumerate}

	\item \textbf{Report on Existing Approach Analysis} - Results of analysis conducted to identify suitable computer vision algorithms/approaches adopted in previously published work, including a statement of the investigation outcomes and justification. 

	\item \textbf{Design Documentation} - Collection of architectural and component-level  designs (including UML sequence, class and use case diagrams) with accompanying descriptions and justifications for choices made.

	\item \textbf{Testing Plan} - Details of testing strategies (with criteria) for the final system, including a specific breakdown and analysis of tests for both the high-level computer vision algorithm(s) and implemented software.
	 
	\item \textbf{Proposed Algorithm(s)} -  Description, discussion and justification of proposed algorithm(s) developed for the project, including details of the approach to testing 	and expected evaluation criteria. 
	
	\item \textbf{Final Implemented System} - The complete system in a working, demonstrable state, that achieves the complete set of finalised tasks. The full source code, in addition to a system demonstration will also be provided.
	
	\item \textbf{Progress Report} - Details of the current state of the project to date, including any changes made to the expected aims, tasks or deliverables (and the reasons for these) and any significant issues encountered with (if possible) descriptions of the solution.

	\item \textbf{Final Report} - Final project report providing a detailed description, discussion and justification of aspects including the design, implementation, deployment and documentation of the final system. Particular focus given to the evaluation of the computer-vision algorithm(s) developed and any future expansions that could be pursued.
		


\end{enumerate}


\nocite{*} % include everything from the bibliography, irrespective of whether it has been referenced.

% the following line is included so that the bibliography is also shown in the table of contents. There is the possibility that this is added to the previous page for the bibliography. To address this, a newline is added so that it appears on the first page for the bibliography. 

\newpage
\addcontentsline{toc}{section}{Initial Annotated Bibliography} 

%
% example of including an annotated bibliography. The current style is an author date one. If you want to change, comment out the line and uncomment the subsequent line. You should also modify the packages included at the top (see the notes earlier in the file) and then trash your aux files and re-run. 
%\bibliographystyle{authordate2annot}
\bibliographystyle{IEEEannot}
\renewcommand{\refname}{Annotated Bibliography}  % if you put text into the final {} on this line, you will get an extra title, e.g. References. This isn't necessary for the outline project specification. 
\bibliography{ops} % References file

\end{document}
